# Emotion-Detection-2.0

Analyze speech and video simultaneously to predict emotions.

## Team Members:
#### 1)Akriti Jain <br />
#### 2)Navya Mamoria <br />
#### 3)Aayush Kumar <br />
#### 4)Suriya R S <br />
#### 5)Chaitanya Gupta <br />

## Introduction

Emotion recognition has become an important topic of research in recent years due to the multiple areas where it can be applied, such as in healthcare or in road safety systems etc. Human emotions can be detected using speech signals, facial expressions and body language. Thus, an algorithm that performs detection, extraction, and evaluation of these features will allow for automatic recognition of human emotion in images and videos.
In the last five years, the field of AI has made major progress in almost all its standard sub-areas, including vision, speech recognition and generation, image and video generation coupled with advancement in various deep learning techniques, now it is possible to predict human emotions with much higher accuracy.


### Prerequisites

-Knowledge of various deep learning techniques like CNN, LSTM etc. <br />
-Some insight into frameworks such as OpenCV, Librosa, Keras, Tensorflow etc


### How AI-Emotion Analysis works

On a high level, an AI emotion application system includes the following steps:<br />

Step #1: Acquire the image frame from a camera feed or extract the audio from .wav file. <br />
Step #2: Preprocessing of the image/audio file (cropping, resizing, color correction, normalisation).<br />
Step #3: Extract the important features with a suitable model<br />
Step #4: Perform emotion classification


### Our Approach


Since both the audio and video parts are independent of each other, two of us (Akriti and Navya) worked on the audio part and the rest (Aayush, Chaitanya and Suriya) worked on the video model. 


### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Add additional notes about how to deploy this on a live system

## Built With

* [Dropwizard](http://www.dropwizard.io/1.0.2/docs/) - The web framework used
* [Maven](https://maven.apache.org/) - Dependency Management
* [ROME](https://rometools.github.io/rome/) - Used to generate RSS Feeds

## Contributing

Please read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.

## Versioning

We use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags). 

## Authors

* **Billie Thompson** - *Initial work* - [PurpleBooth](https://github.com/PurpleBooth)

See also the list of [contributors](https://github.com/your/project/contributors) who participated in this project.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc
